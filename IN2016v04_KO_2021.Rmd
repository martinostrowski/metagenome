---
title: "R Notebook"
output: html_notebook
---

load libraries
```{r}

library(knitr)
library(vegan)
library(ggrepel)
library(randomcoloR)
library(tidyverse)
library(ggridges)
library(oce)
library(scico)
library(hues)
```


The input data consists of gene predictions from assembled contigs. A Last Common Ancestor algorithm  was used to assign contig sequences to NCBI taxa (NCBI non-redundant database Nov2020) at the level where the majority of comparisons agree. The abundance data was generated by mapping reads against both the assembled contigs and the gene predictions. The metrics for each comparison, which are important for different analyses, are differentiated with either a c 'contigs' or a g 'genes' prefix.  taxonomic assignments of the longer contig sequences improved the proportion of the library that could by assigned to taxa, which enabled more of the taxonomic information to be retained for the differential gene abundance analyses.

Functional annotation was undertaken against a selection of databases with a preference for databases with a hierarchal structure, good documentation and accessible tools. These include eggNOG, pfam, tigrFam and the SEED databases using blastp, diamond and hmmsearches, as appropriate, and relevant pipelines where available (e.g. eggNOG mapper, enrichM).

Datasets, in the form of separate gene abundance tables incorporating the taxonomic and functional assignments and abundance data will be prepared in .csv and .biom format for import into popular analysis packages for further analyses (e.g. Metagenomeseq)

1. SEED
2. KO
3. COG/NOG

### preparation and data import


### 01. Gene abundance section

```{r}
setwd('~/IN2016v04data/')


bbmap.files<-list.files(pattern='gene.500.rpkm')
bbmap.files.df<-as.data.frame(bbmap.files)
bbmap.files.df <- separate(bbmap.files.df, bbmap.files, c('code',NA,NA,NA), sep='\\.', remove=F)
bbmap.list <- lapply(bbmap.files.df$bbmap.files,  function(x) read_tsv(x, comment='#', 
                                                                       col_names=c("code_contig_gene",  "gLength",	"gBases",	"gCoverage",    "gReads",	"gRPKM",        "gFrags",	"gFPKM")))

names(bbmap.list) <- bbmap.files.df$code
for (i in seq_along(bbmap.list)){
bbmap.list[[i]] <- mutate(bbmap.list[[i]], 'code'= names(bbmap.list)[i])
}
for (i in seq_along(bbmap.list)){
print(head(bbmap.list[[i]]))}


bbmap <- bind_rows(bbmap.list)
bbmap <- bbmap %>% separate(code_contig_gene, c('code', 'contig', 'gene'), sep='_', remove=F)  %>% unite('contig_id', c(code, contig), sep='_', remove=F)

write_csv(bbmap, 'in2016v04_bbmap_gene_summary.csv')

grpkms <- bbmap
#grpkms<- read_csv('/Volumes/Dropbox/MarineMicrobes Dropbox/Martin Ostrowski//bbmap_gene_summaryv2.csv')

```
### 02. Taxonomy section
```{r}

setwd('/Volumes/Dropbox/MarineMicrobes Dropbox/Martin Ostrowski/IN2016v04data/')

basta.files<-list.files(pattern='.basta$')
basta.files.df<-as.data.frame(basta.files)
basta.files.df <- separate(basta.files.df, 'basta.files', c('code'), sep='_', remove=F)
basta.list <- lapply(basta.files.df$basta.files, function(x) read_tsv(x, col_names=c('contig_id', 'cLCA', 'cBHT')))

names(basta.list) <- basta.files.df$code
for (i in seq_along(basta.list)){
basta.list[[i]] <- mutate(basta.list[[i]], 'code'= names(basta.list)[i])
}

for (i in seq_along(basta.list)){
print(head(basta.list[[i]]))}
basta <- bind_rows(basta.list)

write_csv(basta, 'in2016_basta_summary.csv')

#tax <- read_csv('/Volumes/Dropbox/MarineMicrobes Dropbox/Martin Ostrowski/IN2016v04data/in2016_basta_summary.csv')
tax <- basta
taxLCA<- select(tax, -cBHT)
taxBHT<- select(tax, -cLCA)

```
### 03. KO section
```{r}
setwd('~/IN2016v04data/')

ko.files<-list.files(pattern='.annotations$')
ko.files.df<-as.data.frame(ko.files)
ko.list <- lapply(ko.files, function(x) read_tsv(x, col_names=c("code_contig_gene","seed_eggNOG_ortholog",
                                                                                                "seed_ortholog_evalue",	
                                                                                                "seed_ortholog_score",	
                                                                                                "predicted_gene_name",	
                                                                                                "GO_terms",	
                                                                                                "KEGG_KOs",	
                                                                                                "BiGG_reactions",	
                                                                                                "Annotation_tax_scope",	
                                                                                                "OGs",	
                                                                                                "bestOG|evalue|score",	
                                                                                                "COG cat",	
                                                                                                "eggNOG annot")))


ko <- bind_rows(ko.list)
mo <- read_tsv('~/MAI_module_paths.tsv')
moC <- read_tsv('~/MAI_module_completeness.tsv')

```
### 04. SEED section

```{r}
seed <- read_tsv('~/allGenesSEEDhierarcy.tsv', col_names = c('code_contig_gene', NA,
                                                                        'figID',
                                                                        'pct_identity',
                                                                        'aln_length','n_of_mismatches', 'gap_openings',
                                                                                                           'q_start',
                                                                                                           'q_end',
                                                                                                           's_start',
                                                                                                           's_end',
                                                                                                           'e_value', 'bit_score',
                                                                                                           'functions','lvl3', 'lvl2', 'lvl1'))

seedSub<- seed %>%  select('code_contig_gene','figID','pct_identity', "functions",'lvl3', 'lvl2', 'lvl1') 


gsummary <- grpkms %>% 
  group_by(code) %>% 
  summarise(lengthT=sum(gLength), 
            basesT=sum(gBases), 
            readsT=sum(gReads), 
            rpkmT=sum(gRPKM), 
            rpkmM=mean(gRPKM)) 

summary <- rpkms %>% 
  group_by(code) %>% 
  summarise(lengthT=sum(Length), 
            basesT=sum(Bases), 
            readsT=sum(Reads), 
            rpkmT=sum(RPKM), 
            rpkmM=mean(RPKM)) 


ggplot(gsummary) + 
    geom_bar(aes(as.factor(code), readsT), stat='identity') + 
    coord_flip() + theme_bw()
```

### 05. Joining and Overview Section
summary <- mutate (summary, 'RPKM'= readsT / ( lengthT/1000 * readsT/1000000 ))

```{r}
grpkms$code <- as.character(grpkms$code)

grpkms<- select(grpkms, c(code_contig_gene, gReads, gLength, gBases))
```
### 06. SEED Section: NOT DONE YET - TBA

skip to the quick vis section


###  07. The following section runs through some summary and visualisation steps to check the sanity of the data before generating the abundance table at the genus level

```{r, fig.width=7, fig.height=8}

iwanthue(100, plot=TRUE)

kosummary <- ko %>%  separate(code_contig_gene, c('code', 'contig','gene'), sep='_', remove=F) %>% 
  unite('contig_id', c('code','contig'), sep='_', remove=F)

kosummary %>% group_by(code) %>% summarise(count=n()) # check that all sasmples are present

colnames(kosummary) [1] <- 'code_contig_gene'
kosummaryBHT <- kosummary %>% left_join(taxBHT)

kosummaryBHT <- left_join(kosummaryBHT %>% select(
-c(contig,gene, contig_id)), grpkms)

write_csv(kosummaryBHT, 'IN2016v04_KO_BHT_Long_20210219.csv')

kosummaryBHT <- read_csv('~/db/Martin Ostrowski/IN2016v04data/IN2016v04_KO_BHT_Long_20210219.csv')

kosub <- kosummaryBHT %>% select(code, seed_eggNOG_ortholog, KEGG_KOs, cBHT, gReads, gLength, gBases) %>% separate(cBHT, c('Kingdom', 'Phylum', 'Order', 'Class', 'Family', 'Genus', 'Species'), sep=';', remove=F)
```

#### 07b. import additional sources of metadata


```{r, fig.width=7, fig.height=8}
MMmeta<-read_csv('~/db/additional_metadata/best_effort_metadata_20200824_MB.csv', guess_max = 5000) #import the current metadata f
MMmeta$code <- as.character(MMmeta$code)
MMmeta$utc_date_sampled_yyyymmdd <- as.Date(MMmeta$utc_date_sampled_yyyymmdd, '%d/%m/%y')
MMetaSub<- MMmeta %>% select(code, 
                             depth_m, 
                             utc_date_sampled_yyyymmdd, 
                             latitude_decimal_degrees, 
                             longitude_decimal_degrees,
                             phosphate_umol_per_l,
                             nitrate_nitrite_umol_per_l,
                             location)

kosub$code <- as.character(kosub$code)
kosub <- left_join(kosub, MMetaSub)


kosubT<- kosub %>% group_by(code) %>% summarise(gReadT=sum(gReads)) # add total mapped reads as a column, can be used in the read normalisation
kosub <- left_join(kosub, kosubT)


write_csv(kosub , '~/db/Martin Ostrowski/IN2016v04data/IN2016v04_koslim_20210222.csv')

```


General vusualisation chunk

```{r, fig.width=7, fig.height=8}
tt1<- ggplot(kosub %>%  filter(!is.na(Genus))) + 
  geom_bar(aes(x=as.factor(code),y=gReads/gReadT, fill=fct_lump(Genus,100,  w=gReads)), stat='identity', position='stack', width=0.8)

tt1  + scale_fill_manual(values=iwanthue(102), name='Top 100 Lineages') + 
  theme_bw() + guides(fill=guide_legend(ncol=2)) +facet_grid(Kingdom ~ .,scales='free' ) + 
  labs(y='total number of reads', x='sample')
ggsave('~/in2016v04_bestHit_taxa_KO_profiles.pdf', height=12, width=12)

tt1<- ggplot(kosub %>%  filter(Kingdom=='Eukaryota', !is.na(Genus), !is.na(depth_m))) + 
  geom_bar(aes(x= cut(depth_m, c(0,40,100,250,500,1000,4000), labels = c('surf', '40 - 100m','-250m', '-500m', '-1000m', '-4000m' )),y=gReads/gReadT, fill=fct_lump(Genus,100,  w=gReads)), stat='identity', position='stack', width=0.8)

tt1  + scale_fill_manual(values=iwanthue(102), name='Top 100 Lineages') + 
  theme_bw() + guides(fill=guide_legend(ncol=5)) +facet_wrap(Kingdom ~location,scales='free' ) + coord_flip() +
  labs(y='total number of reads', x='sample') + scale_y_reverse() +theme_light() +theme(legend.position='bottom',  strip.text.y = element_text(angle = 0), panel.spacing.y = unit(0.025,"cm")) 
ggsave('~/in2016v04_bestHit_taxa_KO_profiles.pdf', height=12, width=12)
```
Overview visualisation chunk

```{r, fig.width=7, fig.height=4}
taxabund <- kosub  %>% filter(!is.na(Genus), ) %>%  mutate('top50G' = fct_lump(Genus ,50, w=gReads/gReadT, other_level = NA)) %>% 
  group_by(top50G, Kingdom, Phylum, Genus, utc_date_sampled_yyyymmdd, depth_m) %>% 
  summarise(RA =sum(gReads/gReadT))
tt2<- ggplot(taxabund) + geom_point(aes(x=utc_date_sampled_yyyymmdd, size=RA, y=top50G, fill=top50G ), pch=21,stroke=0.1, alpha=0.7) +
  facet_grid(Phylum ~ .,scales='free', space='free') + 
   labs( y= 'Top 50 Genera by #reads', x='Date')
tt2  + scale_fill_manual(values=iwanthue(60)) + scale_fill_manual(values=iwanthue(60))  + guides(fill=guide_legend(ncol=2), name='Top 50 Lineages') + 
  scale_size_area(max_size = 20, breaks=c(0.001, 0.01, 0.1,0.2)) + 
  theme_light() +theme(legend.position='none',  strip.text.y = element_text(angle = 0), panel.spacing.y = unit(0.025,"cm")) 
ggsave('~/in2016v04_bestHit_taxa_KO_profilesAlt.pdf', height=20, width=12)
```

Euk visualisation chunk

```{r, fig.width=7, fig.height=8}
taxabundEuk <- kosub  %>% filter(!is.na(Genus), Kingdom=='Eukaryota') %>%  mutate('top50G' = fct_lump(Genus ,50, w=gReads/gReadT, other_level = NA)) %>% group_by(top50G, Kingdom, Phylum, Genus, utc_date_sampled_yyyymmdd, depth_m) %>% summarise(RA =sum(gReads/gReadT))
     
tt3<- ggplot(taxabundEuk %>% filter(!is.na(top50G))) + 
  geom_point(aes(x=utc_date_sampled_yyyymmdd, size=RA, y=top50G, fill=top50G ), pch=21,stroke=0.1, alpha=0.7) +
  facet_grid(Phylum ~ .,scales='free', space='free') + 
  labs( y= 'Top 50 Genera by #reads', x='Date')
tt3  + scale_fill_manual(values=iwanthue(60))  + guides(fill=guide_legend(ncol=2), name='Top 50 Lineages') + 
  scale_size_area(max_size = 20, breaks=c(0.001, 0.01, 0.1,0.2)) + 
  theme_light() +theme(legend.position='none',  strip.text.y = element_text(angle = 0), panel.spacing.y = unit(0.025,"cm")) 

ggsave('~/in2016v04_EUK_bestHit_taxa_KO_profiles.pdf',  height=12, width=12)
```

Cyano Visualisation chunk

```{r, fig.width=7, fig.height=5}
taxabundCyano <- kosub  %>% filter(!is.na(Genus), Phylum=='Cyanobacteria') %>%  mutate('top20G' = fct_lump(Species ,20, w=gReads/gReadT, other_level = NA)) %>% group_by(top20G, Phylum, Genus,Species, utc_date_sampled_yyyymmdd, depth_m) %>% summarise(RA =sum(gReads/gReadT))

tt4<- ggplot(taxabundCyano %>% filter(!is.na(top20G))) + 
  geom_point(aes(x=utc_date_sampled_yyyymmdd, size=RA, y=top20G, fill=top20G ), pch=21,stroke=0.1, alpha=0.7) +
  facet_grid(Phylum ~ .,scales='free', space='free') + 
  labs( y= 'Top 50 Species by #reads', x='Date')
tt4  + scale_fill_manual(values=iwanthue(60))  + guides(fill=guide_legend(ncol=2), name='Top 20 Lineages') + 
  scale_size_area(max_size = 20, breaks=c(0.001, 0.01, 0.1,0.2)) + 
  theme_light() +theme(legend.position='none',  strip.text.y = element_text(angle = 0), panel.spacing.y = unit(0.025,"cm")) 

ggsave('~/in2016v04_cyano_bestHit_taxa_KO_profiles.pdf',  height=12, width=12)
```

Proteo visualisation chunk
```{r, fig.width=7, fig.height=5}
taxabundProteo <- kosub  %>% filter(!is.na(Genus), Phylum=='Proteobacteria') %>%  mutate('top30G' = fct_lump(Species ,30, w=gReads/gReadT, other_level = NA)) %>% group_by(top30G, Phylum, Genus,Species, utc_date_sampled_yyyymmdd, depth_m) %>% summarise(RA =sum(gReads/gReadT))

tt5<- ggplot(taxabundProteo %>% filter(!is.na(top30G))) + 
  geom_point(aes(x=utc_date_sampled_yyyymmdd, size=RA, y=top30G, fill=top30G ), pch=21,stroke=0.1, alpha=0.7) +
  facet_grid(Phylum ~ .,scales='free', space='free') + 
  labs( y= 'Top 30 Species by #reads', x='Date')
tt5  + scale_fill_manual(values=iwanthue(60))  + guides(fill=guide_legend(ncol=2), name='Top 30 Lineages') + 
  scale_size_area(max_size = 20, breaks=c(0.001, 0.01, 0.1,0.2)) + 
  theme_light() +theme(legend.position='none',  strip.text.y = element_text(angle = 0), panel.spacing.y = unit(0.025,"cm")) + ggtitle('IN2016v04 Proteobacteria abundance from shotgun metagenomes')


ggsave('~/in2016v04_Proteo_bestHit_taxa_KO_profiles.pdf', height=7, width=9)
```

### 08. Next steps: general statistical overview

The next section prepares a gene abundance table based on the number of reads mapping. 

AT this stage we should consider that the Long format table is the main source of gene counts and total reads mapped per sample. If necessary the other pieces of data can be sourced from the original long format table
```{r, fig.width=7, fig.height=4}

#kotable <- kosummaryBHT[seq(1, nrow(kosummaryBHT), 10),] %>% select(c("seed_eggNOG_ortholog","KEGG_KOs", "eggNOG annot", "gReads","code", "cBHT")) %>% pivot_wider( names_from = code, values_from = gReads, values_fn = sum, values_fill=0)

kotable <- kosummaryBHT %>% select(c("seed_eggNOG_ortholog","KEGG_KOs", "eggNOG annot", "gReads","code", "cBHT")) %>% 
  pivot_wider( names_from = code, values_from = gReads, values_fn = sum, values_fill=0)
kotable$sums <- rowSums(kotable[,5:70])
kotable<- arrange(kotable, desc(sums)) # arranging the table by total abundance 

komat <- as.matrix(kotable[,c(5:70)])
rownames(komat) <- kotable$seed_eggNOG_ortholog
komatSub <- komat[c(1:100000),]

koNMDS <- metaMDS(t(komatSub))

koMDSdf <- as.data.frame(koNMDS$points) %>% rownames_to_column('code') %>% 
  left_join(MMmeta) %>% 
  arrange(utc_date_sampled_yyyymmdd)

ggplot(koMDSdf %>% filter(depth_m < 501)) + geom_point(aes(x=MDS1, color=depth_m, fill=temperature_deg_c, y=MDS2), pch=21, stroke=0.5,  stroke=2, size=4) + theme_light() + 
  scale_fill_gradientn(colors=scico(n=100, palette='lajolla')) + scale_color_gradientn(colors=scico(n=100, palette='berlin')) +
  geom_path(aes(x=MDS1, y=MDS2), alpha=0.2) + geom_text_repel(aes(label=location, x=MDS1,y=MDS2))

ggsave('IN2016v04_dirty_OG_nmds_20210219.pdf')

```


```{r, fig.width=7, fig.height=4}

ggplot(koMDSdf %>% filter(depth_m==2)) + geom_point(aes(x=MDS1, y=utc_date_sampled_yyyymmdd, fill=temperature_deg_c, color=MDS2), pch=21, stroke=0.5,  stroke=2, size=4) + theme_light() + 
  scale_fill_gradientn(colors=scico(n=100, palette='lajolla')) + scale_color_gradientn(colors=scico(n=100, palette='berlin')) +
  geom_path(aes(x=MDS1, y=utc_date_sampled_yyyymmdd), alpha=0.2) + geom_text_repel(aes(label=month.abb[month], x=MDS1,y=utc_date_sampled_yyyymmdd)) + coord_flip()

ggsave('IN2016v04_MDS1_OG_profiles3500.pdf', height=5, width=7)

```


```{r, fig.width=7, fig.height=4}

ggplot(koMDSdf %>% filter(depth_m==2)) + geom_point(aes(x=MDS2, y=utc_date_sampled_yyyymmdd, fill=temperature_deg_c, color=MDS1), pch=21, stroke=0.5,  stroke=2, size=4) + theme_light() + 
  scale_fill_gradientn(colors=scico(n=100, palette='lajolla')) + scale_color_gradientn(colors=scico(n=100, palette='berlin')) +
  geom_path(aes(x=MDS2, y=utc_date_sampled_yyyymmdd), alpha=0.2) + geom_text_repel(aes(label=month.abb[month], x=MDS2,y=utc_date_sampled_yyyymmdd)) + coord_flip()


ggsave('IN2016v04_MDS2_OG_profiles3500.pdf', height=5, width=7)
```

### Clustering de novo, or import a priori clusters from e.g. 16S simprof. BYO clusters and left join them to thhe koMDSdf

```{r}

cl6<- kmeans(sqrt(t(komatSub)), 6)

cl10<- kmeans(sqrt(t(komatSub)), 10)

koMDSdf$cl6 <- cl6$cluster
koMDSdf$cl10 <- cl10$cluster

ggplot(koMDSdf) + geom_point(aes(x=latitude_decimal_degrees, y=utc_date_sampled_yyyymmdd, fill=as.factor(cl10), color=depth_m), pch=21, stroke=0.5,  stroke=2, size=4) + theme_light() + 
  scale_color_gradientn(colors=scico(n=100, palette='berlin')) + #  scale_fill_gradientn(colors=scico(n=100, palette='lajolla'))
  geom_path(aes(x=latitude_decimal_degrees, y=utc_date_sampled_yyyymmdd), alpha=0.2) + geom_text_repel(aes(label=depth_m, x=latitude_decimal_degrees,y=utc_date_sampled_yyyymmdd)) 

ggplot(koMDSdf) + geom_point(aes(x=MDS1, y=MDS2, fill=as.factor(cl10), color=depth_m), pch=21, stroke=0.5,  stroke=2, size=4) + theme_light() + 
  scale_color_gradientn(colors=scico(n=100, palette='berlin')) + #  scale_fill_gradientn(colors=scico(n=100, palette='lajolla'))
  geom_path(aes(x=MDS1, y=MDS2), alpha=0.2) + geom_text_repel(aes(label=depth_m, x=MDS1,y=MDS2)) 



ggplot(koMDSdf %>% filter(depth_m==2)) + geom_point(aes(x=MDS1, color=utc_date_sampled_yyyymmdd, fill=as.factor(cl6), y=MDS2), pch=21, stroke=0.5,  stroke=2, size=4) + theme_light() + 
 scale_color_gradientn(colors=scico(n=100, palette='berlin')) + #  scale_fill_gradientn(colors=scico(n=100, palette='lajolla')) +
  geom_path(aes(x=MDS1, y=MDS2), alpha=0.2) + geom_text_repel(aes(label=month.abb[month], x=MDS1,y=MDS2))
ggplot(koMDSdf) + geom_point(aes(x=utc_date_sampled_yyyymmdd, color=depth_m, fill=temperature_deg_c, y=MDS2), pch=21, stroke=1, size=2) + theme_light() + scale_fill_gradientn(colors=scico(n=100, palette='lajolla')) 


```
### Hypthesis testing Section

Below this line id codaseq centred log ratio code from Brown

instead we are going to run DESeq2, (metagenomeSeq), and then potentially others

***

```{r}



koMDSdf


f_MAI_1 <- codaSeq.filter(t(komatSub), min.reads=8, min.prop=0.0001, min.occurrence = 0.001,samples.by.row=TRUE)

f_MAI_1.x <- aldex.clr(f_MAI_1, conds1, mc.samples=85, verbose=FALSE)


f2.t <- aldex.ttest(f2.x)
f_MAI_1.t <- aldex.ttest(f_MAI_1.x)
f_MAI_2.t <- aldex.ttest(f_MAI_2.x)
f_MAI_5.t <- aldex.ttest(f_MAI_5.x)
f_MAI_4.t <- aldex.ttest(f_MAI_4.x)
f_MAI_5.t <- aldex.ttest(f_MAI_5.x)
f_MAI_7.t <- aldex.ttest(f_MAI_7.x)
f_MAI_8.t <- aldex.ttest(f_MAI_8.x)
f_MAI_9.t <- aldex.ttest(f_MAI_9.x)
f_MAI_10.t <- aldex.ttest(f_MAI_10.x)
f_MAI_11.t <- aldex.ttest(f_MAI_11.x)
f_MAI_12.t <- aldex.ttest(f_MAI_12.x)
# select 'significant' features

#low.p <- which(f.t$we.eBH < 0.05)
#high.e <- which(abs(f.e$effect) >=1)
low.p <- which(f2.t$we.eBH < 0.05)
high.e <- which(abs(f2.e$effect) >1)


#lowp returned 0 values - loosen stringency

low.p2 <- which(f2.t$we.eBH < 0.1)
#[1]  18  96 130 133 151 160 319 354 680 984
row.names(f2.t[c(18,96,130,133,151,160,319,354,680,984),])
#[1] "Bc1000020" "Bc1000130" "Bc1000194" "Bc1000198" "Bc1000234" "Bc1000251" "Bc1000585" "Bc1000693" "Bc1002099" "Bc1004369"

taxonomy$ASVid[Bc1000020]



######Jan
low.p <- which(f_MAI_1.t$we.eBH < 0.05)
[1] 186 231 237 315
high.e <- which(abs(f_MAI_1.e$effect) >1)
# basically everything
row.names(f_MAI_1.t[c(186,231,237,315),])
[1] "Bd1000960" "Bd1001743" "Bd1001803" "Bd1005467"
taxonomy3[which (taxonomy3$ASVid.x == "Bd1000960"),]
Porticoccaceae
taxonomy3[which (taxonomy3$ASVid.x == "Bd1001743"),]
Micropelagos_thuwalensis(RS_GCF_000469155.1)
taxonomy3[which (taxonomy3$ASVid.x == "Bd1001803"),]
Gammaproteobacteria
taxonomy3[which (taxonomy3$ASVid.x == "Bd1005467"),]
Luminiphilus_sp000227505(RS_GCF_000227505.1)

```

repeat for KO
```{r, fig.width=20, fig.height=20}

table(summary_Level2$lvl1)

ggplot(summary_Level2) + geom_bar(aes(x=code, y=totalavcov, fill=lvl2), stat='identity') + theme_bw()

mycolpal <- c("#0000FF", "#800080", "#4B0082", "#808080", "#000000", "#3783FF", "#2AD4FF", "#000080", "#4DE94C", "#008033", "#FFFF00", "#FF8C00", "#FF0000", "#FF0066")

mycolours.pal <- sort(randomColor(401))

summary_Level2 <- summary_Level2 %>% separate(cLCA, c('Kingdom', 'Phylum', 'Order', 'Class', 'Family', 'Genus', 'Species'), sep=';', remove=F)

ggplot(summary_Level2 %>% filter(depth_m == 2, lvl1 %in% c("Photosynthesis", "Stress Response", "Membrane Transport", "Sulfur Metabolism",  "Motility and Chemotaxis", "Phages, Prophages, Transposable elements", "Iron acquisition and metabolism", "Phosphorus Metabolism", "Virulence", "Carbohydrates"),cLCA != 'Unknown')) + 
  geom_point(aes(x=utc_date_sampled_yyyymmdd, size=totalavcov, y=fct_lump(Species, 60, w=totalavcov), fill=fct_lump(Genuss, 60, w=totalavcov)), pch=21, stroke=0.1) + 
  facet_grid(lvl2 ~Kingdom, scales='free', space='free') + 
  theme_bw() +
  scale_fill_manual(values=mycolours.pal) + 
  theme(legend.position='bottom',  strip.text.y = element_text(angle = 0), panel.spacing.y = unit(0.01,"cm")) + 
  guides(fill=guide_legend(ncol=2)) +
  scale_size_area(max_size=40) 


summary_Level2 %>% distinct(cLCA, .keep_all =T) %>% arrange(cLCA) %>% distinct(Genus) %>% pull(Genus)

summary_Level2$Genuss <- factor(summary_Level2$Genus, levels=unique(summary_Level2 %>%  distinct(Genus, .keep_all =T) %>% arrange(cLCA)  %>% pull(Genus)))


ggsave('~/taxonomic_overview_mai.pdf', height=20, width=18)

```

```{r, fig.width=18, fig.height=12}





genus <- ggplot(summary_Level2 %>% filter(lvl1=="Membrane Transport",depth_m == 2,  !is.na(Genus))) + 
  geom_point(aes(x=utc_date_sampled_yyyymmdd, size=totalavcov, y=fct_lump(Species, 60, w=totalavcov), fill=fct_lump(Genuss,60, w=totalavcov)), pch=21, stroke=0.1) + 
  facet_grid(lvl2 ~ ., scales='free', space='free') + 
  theme_bw() +
  scale_fill_manual(values=mycolours.pal) + 
  theme(legend.position='bottom',  strip.text.y = element_text(angle = 0), panel.spacing.y = unit(0.01,"cm")) + 
  guides(fill=guide_legend(ncol=2)) +
  scale_size_area(max_size=60) 



genus  +guides(fill=guide_legend(ncol=3))

library(randomcoloR)
ggplot(summary_Level2) + geom_bar(aes(x=code, y=totalavcov, fill=lvl2), stat='identity') + theme_bw()

mycolpal <- c("#0000FF", "#800080", "#4B0082", "#808080", "#000000", "#3783FF", "#2AD4FF", "#000080", "#4DE94C", "#008033", "#FFFF00", "#FF8C00", "#FF0000", "#FF0066")

mycolours.pal <- randomColor(966)

ggplot(summary_Level3) + geom_bar(aes(x=utc_date_sampled_yyyymmdd, y=totalavcov, fill=lvl3), stat='identity', position='fill') + theme_bw() +facet_grid(depth_m ~ .) + scale_fill_manual(values=mycolours.pal) + theme(legend.position='none')

```
```


```{r}
sort(rowSums(seedSub_coverage_wider[, -c(1:5)]))

seedmat <- seedSub %>%  pivot_wider(names_from = 'code_contig_gene',values_from =  )

?pivot_wider()






#Set up a wide format table of the top 1000 ASV by abundance in the current table 
#use MAI_0M
pelB <- read_csv('/Users/mvb815/MarineMicrobes Dropbox/amplicons2020/MarineBgtdbCore20200713.csv')
pelBx <- read_csv('/Users/mvb815/MarineMicrobes Dropbox/amplicons2020/pelagicB.tablelong.22Jul.2020.csv')
meta <- read_csv('/Users/mvb815/MarineMicrobes Dropbox/amplicons2020/AMI_metadata_20200710_MO.csv')
meta2 <- subset(meta[,c(1,2,3,4,10,169)])
pelBx2 <- left_join(pelBx, meta2, by="code")

#
hw_data <- read.csv('/Users/mvb815/MarineMicrobes Dropbox/CTI_2020/Heatwaves/heatwavedatafromthenrss/Heatwave_samples_15Jun2020.csv')
metadata_hw <- left_join(metadata, hw_data,by='code') # join metadata with heatwave info#identifies samples in heatwaves only - not those not in a heatwave

#to change date into day month year
pelB <- pelB %>% separate(utc_date_sampled_yyyymmdd, c("year", "month", "day"), sep="-", remove=F)
pelBx2$utc_date_sampled_yyyymmdd <- as.Date(pelBx2$utc_date_sampled_yyyymmdd, format = c("%d/%m/%y")) #conveert date
pelBx2 <- pelBx2 %>% separate(utc_date_sampled_yyyymmdd, c("year", "month", "day"), sep="-", remove=F)
pelB$month <- as.numeric(pelB$month)
pelBx2$month <- as.numeric(pelBx2$month)

meta2_MAI$utc_date_sampled_yyyymmdd <- as.Date(meta2_MAI$utc_date_sampled_yyyymmdd, format = c("%d/%m/%y"))
meta2_MAI<- meta2_MAI %>% separate(utc_date_sampled_yyyymmdd, c("year", "month", "day"), sep="-", remove=F)
meta2_MAI$month <- as.numeric(meta2_MAI$month)


pelBx2$depth_m[pelBx2$code == 139740] <- 0
pelBx2$depth_m[pelBx2$code == 139741] <- 0


```

Organise data
```{r}
MAI_surface_spread <- pelB %>% filter(uniqcode %in% c('MAI')) %>% filter(depth_m <11) %>% 
  dplyr::select(ASVid, abund, code) %>% 
  spread(key=ASVid, value= abund, fill=0) # select 0 and 10m samples from MAI and spread table to wide format
#...

```

### 06. The missing SEED section
```{r}
seedSub_coverageG <- seedSub_coverage %>%  select(-c(pid)) %>%   left_join(grpkms)

summaryseed<-seedSub_coverage %>% group_by(code) %>% summarise(count=n()) #check that all metagenomes have been processed

seedSub_coverageG <- seedSub %>% 
  separate('code_contig_gene', c('code', 'contig','gene'), sep='_', remove=F) %>% 
  unite('contig_id', c('code','contig'), sep='_', remove=F) #prepare `contig_id` to match the taxonomic assignment of contigs
summaryBHT <- taxBHT %>% 
  separate('contig_id', c('code', 'contig'), sep='_', remove=F) %>% 
  group_by(code) %>% summarise(count=n())

#colnames(seedSub_coverage)

seedSub_coverage_widerLCA <- seedSub_coverageG %>%  
  select(contig_id, figID, code, functions, lvl3, lvl2, lvl1, gReads, gFPKM) %>% 
  left_join(taxLCA)

seedSub_coverage_widerBHT <- seedSub_coverageG %>%  
  select(contig_id, figID, code, functions, lvl3, lvl2, lvl1, gReads) %>% 
  left_join(taxBHT)


seedSub_coverage_widerPlca <- seedSub_coverage_widerLCA %>% 
  filter(!is.na(cLCA)) %>%  
  pivot_wider(c(cLCA,figID,functions,lvl1, lvl2, lvl3), names_from = code, values_from=gReads, values_fn=sum, values_fill=0)

seedSub_coverage_widerPbht <- seedSub_coverage_widerBHT %>% 
  filter(!is.na(cBHT)) %>%  
  pivot_wider(c(cBHT,figID,functions,lvl1, lvl2, lvl3), names_from = code, values_from=gReads, values_fn=sum, values_fill=0)

seedSub_coverage_widerP <- seedSub_coverage_widerP %>% 
  separate(cLCA, c('Kingdom', 'Phylum', 'Order', 'Class', 'Family', 'Genus', 'Species'), sep=';', remove=F)

seedSub_coverage_widerbhtP <- seedSub_coverage_widerPbht %>% 
  separate(cBHT, c('Kingdom', 'Phylum', 'Order', 'Class', 'Family', 'Genus', 'Species'), sep=';', remove=F)

seedSub_coverage_widerP <- seedSub_coverage_widerP %>% 
  separate(cLCA, c('Kingdom', 'Phylum', 'Order', 'Class', 'Family', 'Genus', 'Species'), sep=';', remove=F)

#seedSub_coverage_wider[is.na(seedSub_coverage_wider)] <- 0


write_csv(seedSub_coverage_widerPbht, '/Volumes/Dropbox/MarineMicrobes Dropbox/MAI/MAI_SEED_profiles_taxBHT.csv')

summary_bht <- seedSub_coverage_widerPbht %>% select(-c(lvl1,lvl2,lvl3, functions)) %>% 
  pivot_longer(-c(figID,cBHT ), names_to = 'code', values_to='TotalReads') %>% 
  group_by(cBHT,figID, code ) %>% 
  summarise(totalreads=sum(TotalReads)) %>% 
  ungroup() %>% 
  arrange(desc(totalreads))
  ```
